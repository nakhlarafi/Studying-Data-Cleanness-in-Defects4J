{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77ba2fbb-a031-4561-aafa-b6bf0f39ccd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "from subprocess import DEVNULL\n",
    "\n",
    "def execute_shell(batch):\n",
    "    if batch is None:\n",
    "        print('something is wrong with subprocess, batch is None')\n",
    "        return None\n",
    "    try:\n",
    "        # unicode_escape\n",
    "        # \n",
    "        output = subprocess.check_output(batch, universal_newlines=True, encoding='ISO-8859-1')\n",
    "        return output\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print('CalledProcessError', e.output)\n",
    "        #sys.exit(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc78275-7272-4f08-a184-e1e32dda8c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #!/usr/bin/env python\n",
    "# # coding: utf-8\n",
    "\n",
    "# # In[1]:\n",
    "\n",
    "\n",
    "# get_ipython().run_line_magic('run', 'corpus.ipynb')\n",
    "\n",
    "# import re\n",
    "# import csv\n",
    "# import sys\n",
    "# import json\n",
    "# from itertools import islice\n",
    "# import subprocess\n",
    "# from os import path\n",
    "\n",
    "# def execute_shell(batch):\n",
    "#     if batch is None:\n",
    "#         print('something is wrong with subprocess, batch is None')\n",
    "#         return None\n",
    "#     output = subprocess.check_output(batch)\n",
    "#     return output\n",
    "\n",
    "# def sort_desc_json(file):\n",
    "#     d = json_to_dict(file)\n",
    "#     sorted_d = sorted(d.items(), key=itemgetter(1), reverse=True)\n",
    "#     dict_to_json_ordered(file, sorted_d)\n",
    "\n",
    "# def sort_desc_nested_json(file, output):\n",
    "#     d = json_to_dict(file)\n",
    "#     odd = OrderedDict([])\n",
    "#     for k_c, files in d.items():\n",
    "#         sorted_files = sorted(files.items(), key=itemgetter(1), reverse=True)\n",
    "#         sorted_d = OrderedDict(sorted_files)\n",
    "#         odd.update({k_c: sorted_d})\n",
    "#     dict_to_json_ordered(output, odd)\n",
    "    \n",
    "# def take_dict(n, iterable):\n",
    "#     \"Return first n items of the iterable as a list\"\n",
    "#     l = list(islice(iterable, n))\n",
    "#     return {i:iterable[i] for i in l}\n",
    "    \n",
    "# def custom_csv(file, rows):\n",
    "#     with open('../output/'+file+'.csv', mode='a') as output:\n",
    "#         corpus_writer = csv.writer(output, delimiter=' ', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "#         corpus_writer.writerow(rows)\n",
    "#     output.close()\n",
    "    \n",
    "# from collections import OrderedDict\n",
    "# def dict_to_json_ordered(file, dic):\n",
    "#     with open('../output/'+file+'.json', 'w') as fp:\n",
    "#         json.dump(OrderedDict(dic), fp, indent=4)\n",
    "#     fp.close()\n",
    "    \n",
    "# def json_to_dict_other(file):\n",
    "#     data = {}\n",
    "#     with open(file, 'r') as fp:\n",
    "#         data = json.load(fp)\n",
    "#     fp.close()\n",
    "#     return data\n",
    "\n",
    "# def dict_to_json_custom(file, dic):\n",
    "#     with open(file, 'w+') as fp:\n",
    "#         json.dump(dic, fp, sort_keys=True, indent=4)\n",
    "#     fp.close()\n",
    "    \n",
    "# def dict_to_json(file, dic):\n",
    "#     with open('../output/'+file+'.json', 'w') as fp:\n",
    "#         json.dump(dic, fp, sort_keys=True, indent=4)\n",
    "#     fp.close()\n",
    "    \n",
    "# def json_to_dict(file):\n",
    "#     data = {}\n",
    "#     with open('../output/'+file+'.json', 'r') as fp:\n",
    "#         data = json.load(fp)\n",
    "#     fp.close()\n",
    "#     return data\n",
    "    \n",
    "# def read_dm_set(file):\n",
    "#     data = {}\n",
    "#     with open('../output/'+file+'.json', 'r') as fp:\n",
    "#         data = json.load(fp)\n",
    "#     fp.close()\n",
    "#     return data\n",
    "    \n",
    "# # only append to csv if rows doesn't exist\n",
    "# def write_csv_custom(file, rows, header):\n",
    "#     with open(file, mode='w+') as output:\n",
    "#         corpus_writer = csv.writer(output, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "#         if header:\n",
    "#             corpus_writer.writerow(header)\n",
    "#         for row in rows:\n",
    "#             corpus_writer.writerow(row)\n",
    "#     output.close()\n",
    "    \n",
    "# # only append to csv if rows doesn't exist\n",
    "# def extend_csv(file, rows):\n",
    "#     with open('../output/'+file+'.csv', mode='r+') as output:\n",
    "#         for line in output:\n",
    "#             if ' '.join(str(x) for x in rows) in line:\n",
    "#                 break\n",
    "#             else:\n",
    "#                 corpus_writer = csv.writer(output, delimiter=' ', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "#                 corpus_writer.writerow(rows)\n",
    "#     output.close()\n",
    "\n",
    "# def rank_dict(dictionary):\n",
    "#     return {key:value for key, value in sorted(dictionary.items(), key = itemgetter(1), reverse = True)}\n",
    "\n",
    "# def rank_dict_to_list(dictionary):\n",
    "#     return [key for key, value in sorted(dictionary.items(), key = itemgetter(1), reverse = True)]\n",
    "\n",
    "# def intersection_dicts(dict_a, dict_b):\n",
    "#     keys_a = set(dict_a.keys())\n",
    "#     keys_b = set(dict_b.keys())\n",
    "#     intersection = keys_a & keys_b\n",
    "#     return {k:dict_a[k] for k in intersection}\n",
    "\n",
    "# def write_to_csv(file, d):\n",
    "#     with open('../output/'+file+'.csv', 'w') as file:\n",
    "#         csv_file = csv.writer(file)\n",
    "#         for key, file_score_pair in d.items():\n",
    "#             ranked = rank_dict_to_list(file_score_pair)\n",
    "#             hit = 0\n",
    "#             for f in ranked:\n",
    "#                 if hit is 0:\n",
    "#                     csv_file.writerow([key, f, file_score_pair[f]])\n",
    "#                     hit = 1\n",
    "#                     continue\n",
    "#                 csv_file.writerow(['', f, file_score_pair[f]])\n",
    "#             csv_file.writerow(['', '', ''])\n",
    "#     file.close()\n",
    "    \n",
    "# def write_to_csv_intersec(file, d, mark):\n",
    "#     with open('../output/'+file+'.csv', 'w') as file:\n",
    "#         csv_file = csv.writer(file)\n",
    "#         for key, file_score_pair in d.items():\n",
    "#             ranked = rank_dict_to_list(file_score_pair)\n",
    "#             hit = 0\n",
    "#             for f in ranked:\n",
    "#                 changed = ''\n",
    "#                 if key in mark and f.split(' ')[0] in mark[key].keys():\n",
    "#                     changed = True\n",
    "#                 if hit is 0:\n",
    "#                     csv_file.writerow([key, f, file_score_pair[f], changed])\n",
    "#                     hit = 1\n",
    "#                     continue\n",
    "#                 csv_file.writerow(['', f, file_score_pair[f], changed])\n",
    "#             csv_file.writerow(['', '', '', ''])\n",
    "#     file.close()\n",
    "    \n",
    "# def write_to_csv_overview(file, top20, epath, changed):\n",
    "#     with open('../output/'+file+'.csv', 'w') as file:\n",
    "#         csv_file = csv.writer(file)\n",
    "#         for key, file_score_pair in top20.items():\n",
    "#             ranked = rank_dict_to_list(file_score_pair)\n",
    "#             if key in epath:\n",
    "#                 ranked_epath = rank_dict_to_list(epath[key])\n",
    "#             else:\n",
    "#                 ranked_epath = []\n",
    "#             if key in changed:\n",
    "#                 ranked_changed = rank_dict_to_list(changed[key])\n",
    "#             else:\n",
    "#                 ranked_changed = []\n",
    "#             hit = 0\n",
    "#             i = 0\n",
    "            \n",
    "#             print(key, ranked_changed, ranked_epath)\n",
    "#             for f in ranked:\n",
    "#                 epath_file = ''\n",
    "#                 epath_file_score = ''\n",
    "#                 changed_file = ''\n",
    "#                 changed_file_score = ''\n",
    "#                 if i < len(ranked_changed):\n",
    "#                     changed_file = ranked_changed[i]\n",
    "#                     changed_file_score = changed[key][ranked_changed[i]]\n",
    "#                 if i < len(ranked_epath):\n",
    "#                     epath_file = ranked_epath[i]\n",
    "#                     epath_file_score = epath[key][ranked_epath[i]]\n",
    "#                 print(i, changed_file, changed_file_score)\n",
    "#                 if hit is 0:\n",
    "#                     csv_file.writerow([key, f, file_score_pair[f], changed_file, changed_file_score, epath_file, epath_file_score])\n",
    "#                     hit = 1\n",
    "#                     i = i + 1\n",
    "#                     continue\n",
    "#                 csv_file.writerow(['', f, file_score_pair[f], changed_file, changed_file_score, epath_file, epath_file_score])\n",
    "#                 i = i + 1\n",
    "#             csv_file.writerow(['', '', '', ''])\n",
    "#     file.close()\n",
    "\n",
    "# def read_tf_idf(file):\n",
    "#     csv.field_size_limit(sys.maxsize)\n",
    "#     tf_idf = {}\n",
    "#     with open(file) as csv_file:\n",
    "#         csv_reader = csv.reader(csv_file, delimiter=' ', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "#         for row in csv_reader:\n",
    "#             token = row[0]\n",
    "#             document = row[1]\n",
    "#             if document not in tf_idf:\n",
    "#                 tf_idf[document] = {}\n",
    "#             tf_idf[document][token] = row[2]\n",
    "#     csv_file.close()\n",
    "#     return tf_idf\n",
    "\n",
    "# def write_bug_csv(voc, id, project):\n",
    "#     with open('../output/bug_corpus/'+project+'.csv', mode='a') as corpus_file:\n",
    "#         corpus_writer = csv.writer(corpus_file, delimiter=' ', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "#         corpus_writer.writerow([id, ' '.join(voc)])\n",
    "#     corpus_file.close()\n",
    "    \n",
    "# def write_csv(corpus, id):\n",
    "#     with open('../output/corpus/'+id+'.csv', mode='a') as corpus_file:\n",
    "#         corpus_writer = csv.writer(corpus_file, delimiter=' ', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "#         corpus_writer.writerow([corpus.get_package(), corpus.get_file(), ' '.join(corpus.get_voc())])\n",
    "#     corpus_file.close()\n",
    "    \n",
    "# def write_csv_dict(corpus_l, id):\n",
    "#     with open('../output/corpus/'+id+'.csv', 'w') as file:\n",
    "#         corpus_writer = csv.writer(file, delimiter=' ', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "#         for corpus in corpus_l:\n",
    "#             corpus_writer.writerow([corpus.get_package(), corpus.get_file(), ' '.join(corpus.get_voc())])\n",
    "#     file.close()\n",
    "\n",
    "# def read_bug_csv(file):\n",
    "#     csv.field_size_limit(sys.maxsize)\n",
    "#     corpus_list = {}\n",
    "#     with open(file) as csv_file:\n",
    "#         csv_reader = csv.reader(csv_file, delimiter=' ', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "#         for row in csv_reader:\n",
    "#             id = row[0]\n",
    "#             voc = row[1].split(' ')\n",
    "#             corpus_list[id] = voc\n",
    "#     return corpus_list\n",
    "    \n",
    "# def read_csv(file):\n",
    "#     csv.field_size_limit(sys.maxsize)\n",
    "#     corpus_list = []\n",
    "#     with open(file) as csv_file:\n",
    "#         csv_reader = csv.reader(csv_file, delimiter=' ', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "#         for row in csv_reader:\n",
    "#             package = row[0]\n",
    "#             file_name = row[1]\n",
    "#             voc = row[2]\n",
    "#             corpus = Corpus()\n",
    "#             corpus.set_voc(voc.split(' '))\n",
    "#             corpus.set_file(file_name)\n",
    "#             corpus.set_package(package)\n",
    "#             corpus_list.append(corpus)\n",
    "#     csv_file.close()\n",
    "#     return corpus_list\n",
    "    \n",
    "# def read_bug_json(file):\n",
    "#     bug_content = None\n",
    "#     with open(file) as json_file:\n",
    "#         data = json.load(json_file)\n",
    "#         bug_content = ' '.join(filter(None, (data['fields']['description'], data['fields']['summary'])))\n",
    "#     json_file.close()\n",
    "#     return bug_content\n",
    "\n",
    "# def sort_dict_descending(dic):\n",
    "#     return {k: v for k, v in sorted(dic.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "# def read_corpus_file(f):\n",
    "#     l = []\n",
    "#     with open('../output/'+f+'.csv') as csv_f:\n",
    "#         csv_reader = csv.reader(csv_f, delimiter='\\n')\n",
    "#         for row in csv_reader:\n",
    "#             l.append(row[0].split('.csv')[0])\n",
    "#     return l\n",
    "\n",
    "# def read_commits():\n",
    "#     commits = {}\n",
    "#     with open('input/issues.csv') as csv_file:\n",
    "#         csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "#         next(csv_reader, None)\n",
    "#         for row in csv_reader:\n",
    "#             key = row[1]\n",
    "#             c = re.findall('[0-9a-f]{40}', row[3])\n",
    "#             commits[key] = c\n",
    "#     csv_file.close()\n",
    "#     return commits\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
